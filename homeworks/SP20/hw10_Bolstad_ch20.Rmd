---
title: "Homework 10: Comp Bayes Stats (Ch.20)"
author: "AG Schissler"
date: "04/17/2020"
output: html_document
---

Please respond to the questions below. I encourage you to collaborate with your classmates, but you must submit your own work. This assignment is due on the date listed above. **If you use `R`, please run `set.seed(04172020)` at the top your script**. This will make the simulations reproducible. If using `knitr` (`.Rmd` file), place the following at the top of the script:

```{r setup, include=TRUE}
knitr::opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=TRUE)
set.seed(04172020)
```

## Question 1: Introduction to sampling the posterior

Refer to Example 20.1. Now suppose that Aisha, Blair, and Chiara observe $y=2$ from a normal sampling model with known $\sigma = 1$. They decide to use a flat, improper prior for $\mu$. Aisha says the posterior, $g(\mu | y)$, with be $normal(2, 1)$. You help Blair by numerically integrating the posterior (Hint: use `integrate` in `R` and use `Inf` in the bounds). Chiara asks you to  implement random sampling from the posterior of sizes 1,000, 10,000, 100,000, and 1,000,000. Replicate Figure 20.1 and Table 20.1 for this setting.

```{r, include=FALSE}
f <- function(mu) {exp( -(mu - 2)^2 /2 )}
integrate(f, Inf, -Inf)
```

## Question 2: Inverse probability sampling

Refer to Example 20.2. A random variable $y$ is distributed $Weibull(\alpha, \lambda)$ if it has cdf $F(y) = 1 - e^{-\lambda y^\alpha}$ for $y > 0$ and $\alpha > 0$. Let $y \sim Weibull(\alpha = 2$ and $\lambda = 3)$. Use *inverse probability sampling* to create a random sample of size 10,000 from this Weibull distribution. Reproduce Figure 20.3 to visualize your sample.

## Question 3: Acceptance-rejection sampling

Refer to Example 20.3. Develop your own *acceptance-rejection* algorithm to take a sample of size 10,000 from a $beta(6,2)$ distribution. Reproduce a figure similar to Figure 20.5 to demonstrate your samples are from the target distribution.

## Question 4: Importance sampling

Refer to Example 20.5. Suppose that you observe $y= 4, 1, 3, 1, 3$. We'll model these $y_i$ as iid $Poisson(\theta)$ and assume a Jeffrey's prior (see Section 10.1, p.195). Use *importance sampling* to obtain the posterior probability that $\theta > 6$.

```{r, include=FALSE}
library(Bolstad)
poisgamp(y =c(4,1,3,1,3), shape = 1/2, rate = 0, alpha = 0.0001)

```

## Question 5: Metropolis-Hastings MCMC for a single parameter

Refer to Example 20.7. Emily finds an unscaled target density that models heights in a population that contains both male and female people. The (unscaled) density is given by  

$g(\theta | y) = 0.51  e^{ - \frac{1}{2} \left( \frac{\theta - 64}{3} \right) ^2 } + 0.49  e^{ - \frac{1}{2} \left( \frac{\theta - 69}{4} \right) ^2 }$.  

Write your own *Metropolis-Hastings* algorithm to sample from this density. Reproduce Figure 20.13 for this setting.
