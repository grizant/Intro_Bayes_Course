---
title: "Hamiltonian MCMC and Fitting Bayesian Multilevel Regression"
author: "Presented by AG Schissler"
date: "04/29/2020"
output: 
  html_vignette:
    toc: yes
---

```{r setup, include=FALSE}
suppressMessages(library(ggplot2))
suppressMessages(library(rstanarm))
suppressMessages(library(bayesplot))
theme_set(bayesplot::theme_default())
suppressMessages(stopifnot(require(knitr)))
opts_chunk$set(
  echo = TRUE,
  comment=NA, 
  message = FALSE, 
  warning = FALSE, 
  eval = TRUE,
  dev = "png",
  dpi = 150,
  fig.asp = 0.618,
  fig.width = 5,
  out.width = "60%",
  fig.align = "center",
  cache=TRUE, 
  autodep=TRUE, 
  cache.comments=TRUE
)
```

# Start-of-class work: MCMC inefficiencies

Watch a Metropolis algorithm "get stuck" on the "donut" example. Discuss why this may be occurring.

[mcmc demo](https://chi-feng.github.io/mcmc-demo/)

# I. Why HMC?

## Overview of MCMC Strategies

- Metropolis: Granddaddy of them all
- Metropolis-Hastings (MH): More general
- Gibbs sampling (GS): Efficient version of MH
- Metropolis and Gibbs are "guess and check" strategies
- Hamiltonian Monte Carlo (HMC) fundamentally different - uses the gradient
- New methods being developed, but future belongs to the gradient

Excellent reference text: Brooks, S., Gelman, A., Jones, G., & Meng, X. L. (Eds.). (2011). *Handbook of markov chain monte carlo.* CRC press.

## Problem with Gibbs sampling (GS)

- High dimension spaces are concentrated
- GS gets stuck, degenerates towards random walk
- Inefficient because re-explores 

## Hamiltonian dynamics to the rescue

- represent parameter state as particle
- flick it around frictionless log-posterior
- record positions
- no more "guess and check", as (nearly) all proposals are good proposals

# II. Brief overview of HMC

From MacKay, David JC. *Information theory, inference and learning algorithms.* Cambridge university press, 2003.

"The HMC method is a Metropolis method, applicable to continuous state spaces, that makes use of gradient information to reduce random walk behavior... It seems wasteful to use a simple random-walk Metropolis method when this gradient is available - the gradient indicates which direction one should go in to find states that have higher probability!"

See MacKay, Section 30.1 for a basic implementation of HMC and mathematical details. Let's return to the MCMC demonstration and I'll discuss the intuition.

* Standard normal ("hill")
* Doughnut (like a "bowl" that follows that shape).

[mcmc demo](https://chi-feng.github.io/mcmc-demo/)

## More HMC readings and instructional materials

- R. McElreath's Statistical Rethinking great overall applied Bayesian modeling and MCMC. [https://github.com/rmcelreath/statrethinking_winter2019](https://github.com/rmcelreath/statrethinking_winter2019)  
- Excellent lecture on MCMC methods including HMC 
[https://speakerdeck.com/rmcelreath/l10-statistical-rethinking-winter-2019](https://speakerdeck.com/rmcelreath/l10-statistical-rethinking-winter-2019)
- M. Betancourt's [A Conceptual Introduction to Hamiltonian Monte Carlo](https://arxiv.org/abs/1701.02434) for a rigorous introduction.

# III. Using software to do HMC

## Stan

- No U-Turn Sampler (NUTS2): Adaptive Hamiltonian Monte Carlo
- Implemented in Stan (rstan: mc-stan.org)
- Stan figures out gradient for you via autodiff

## Problem with regular HMC U-turns

* Increase leapfrog steps in regular HMC on normal density
* Doughnut (like a "bowl" that follows that shape)

[mcmc demo](https://chi-feng.github.io/mcmc-demo/)

## Advantages of Stan

Derived from 

Gelman, Andrew, Daniel Lee, and Jiqiang Guo. "Stan: A probabilistic programming language for Bayesian inference and optimization." Journal of Educational and Behavioral Statistics 40.5 (2015): 530-543.

"Stan was motivated by the desire to solve problems that could not be solved in reasonable time
(user programming time plus run time) using other packages.

In comparing Stan to other software options, we consider several criteria:
1. Flexibility, that is, being able to fit the desired model.
2. Ease of use; user programming time.
3. Run time.
4. Scalability as dataset and model grow larger."

## A walkthrough of using `rstan` for multilevel modeling of `eight schools` data

[http://mc-stan.org/rstan/articles/rstan.html](http://mc-stan.org/rstan/articles/rstan.html)  

- `Stan` and `rstan` provide fine control for HMC sampling for customized and elaborate models.  
- On the other hand, `rstanarm` provides a `glmer` style interface for rapid model development.  
- The `rethinking` package also has a user-friendly interface to specify `stan` models (see the `ulam` function below).

## Some good rstan/stan links

- [https://mc-stan.org/users/documentation/index.html](https://mc-stan.org/users/documentation/index.html)  
- [https://mc-stan.org/users/documentation/case-studies.html](https://mc-stan.org/users/documentation/case-studies.html)  
- [https://mc-stan.org/users/documentation/case-studies/rstan_workflow.html](https://mc-stan.org/users/documentation/case-studies/rstan_workflow.html)  
- [https://nbviewer.jupyter.org/github/QuantEcon/QuantEcon.notebooks/blob/master/IntroToStan_basics_workflow.ipynb](https://nbviewer.jupyter.org/github/QuantEcon/QuantEcon.notebooks/blob/master/IntroToStan_basics_workflow.ipynb)  
- [http://modernstatisticalworkflow.blogspot.com/2017/04/an-easy-way-to-simulate-fake-data-from.html](http://modernstatisticalworkflow.blogspot.com/2017/04/an-easy-way-to-simulate-fake-data-from.html)  

## A tour of the `rstanarm` package

- I'll give tour of the `rstanarm` package. 
- This package offers a `glmer` style syntax to do NUTS HMC. 
- It mirrors the `arm` package and should be a solid choice for your last HW.
- It has great built-in visualization, default prior choices, and community/documentation.
- Lots of example code at [https://github.com/stan-dev/rstanarm](https://github.com/stan-dev/rstanarm).

### Single-level regression for continuous outcomes

```{r rstanarm1, eval=FALSE}
## list vignettes
vignette(package = 'rstanarm')
vignette(topic = 'continuous',  package = 'rstanarm')
```

### Setting priors

```{r rstanarm2, eval=FALSE}
vignette(topic = 'priors',  package = 'rstanarm')
```

### Detailed use

```{r rstanarm3, eval=FALSE}
vignette(topic = 'rstanarm',  package = 'rstanarm')
```

### Partial pooling

```{r rstanarm4, eval=FALSE}
vignette(topic = 'pooling',  package = 'rstanarm')
```

### Code from Gelman and Hill textbook

You may find the following demonstrations useful when completing your HW.

```{r rstanarm5, eval=FALSE}
demo(package = 'rstanarm')
demo(topic = 'ARM_Ch12_13',  package = 'rstanarm')
```

## `greta` High performance Bayesian inference software

- Greta is built over Google TensorFlow.  
- It's incredible, but not a huge community of users yet (so you have to write your own code instead of Googling).  
- [Greta](https://greta-stats.org/)  

# IV. Check the chains: diagnostics and a way to fix

## Sometimes it doesnâ€™t work

* Good chains
  * Converge to same target distribution
  * Once there, explore efficently 
* Different ways to check
  * Trace plots
  * Convergence diagnostics (n_eff , Rhat)
  * Special warnings (divergent transitions)

## Trace plot

* Check first
* Shows some problems not all
* want to see a "hairy caterpillar"

## Convergence diagnostics

* n_eff: "effective" number of samples
  * n_eff / n < 0.1, be alarmed
* R-hat
  * R-hat: crudely, ratio of variance between chains to variance within chains
  * Should approach 1
* Both diagnostics can mislead


## A wild chain

```{r}
## install from github using devtools
## library(devtools); devtools::install_github("rmcelreath/rethinking")
## https://github.com/rmcelreath/rethinking
suppressMessages(library(rethinking))
y <- c(-1, 1)
set.seed(11)
m9.2 <- ulam(
    alist(
        y ~ dnorm( mu, sigma ),
        mu <- alpha,
        alpha ~ dnorm(0, 1000) ,
        sigma ~ dexp( 0.0001)
    ),
    data = list(y = y), chains = 2)
    
```

```{r}
precis( m9.2 )
```

```{r}
traceplot( m9.2 )
```

* The problem is (nearly) flat priors that encourages the sampler to explore a log-posterior out to the thousands...
* This is one reason Maximum Likelihood Estimation can be a problematic!
* Also a problem for Gibbs.
* Weakly informative priors to the rescue

## A tame chain

```{r}
set.seed(11)
m9.3 <- ulam(
    alist(
        y ~ dnorm( mu, sigma ),
        mu <- alpha,
        ## even include a "bad" starting point
        alpha ~ dnorm(1, 10) ,
        sigma ~ dexp( 1)
    ),
    data = list(y = y), chains = 2)
    
```

```{r}
precis( m9.3 )
```

```{r}
traceplot( m9.3 )
```

## "Folk Theorem" of statistical computing

![Prof Andrew Gelman says to heed it](folk_theorem.png){#id .class width=500 height=500px}

# V. Visualization in Bayesian model development

This is a good workflow to employ:

Gabry et al [Visualization in Bayesian workflow](https://arxiv.org/pdf/1709.01449.pdf)

The four basic steps are

1) Specify a posterior distribution (by specifying the priors and likelihood).  
2) Draw from the posterior distribution. You should generate **fake data** to ensure this is working properly.  
3) Critize the model. You should compare  **predictons to the data** to assess the quality of the model.  
4) Analyze manipulations of predictors and parameters. Use to the posterior samples to conduct **statistical inference**. Such as, credible intervals, posterior predictions, Bayesian hypothesis testings, etc.

# Closing

In what situations do we need to use more advanced and efficient MC algorithms?
