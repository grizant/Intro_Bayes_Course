---
title: "Introduction to probability"
author: "AG Schissler"
date: "01/28/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Start-of-class work (5 - 10 min)

### Recalling probability terms

Please define and notate (when appropriate) without referring to the text or Internet. You may discuss with those around you.

1. Random experiment
2. Outcome
3. Sample space. What are two ways to denote it?
4. Event
5. Union of two events. What symbol is used?
6. Intersection of two events. What symbol is used?
7. Complement of an event. What symbol is used?

## I. Discuss learning outcomes from meeting 1 (15 min)

Let's revisit [1_intro.html](http://www.grantschissler.com/teaching/SP19/STAT429/1_intro.html) to discuss learning outcomes and assessment.

## II. Discus deductive logic and plausible reasoning (10 min)

(from Bolstad & Curran Ch.4, Section 4.1, p.59)

Probability formalizes plausible reasoning, extending logic to account for uncertainty. Deductive reasoning is the most typically presented way to prove statements. It works by flowing from the general to particular. It does a poor job of dealing with uncertainty! 

Induction, on the other hand, flows from the particular to the general. (Do you recall proving something by assuming a base case and prove the next case must hold the statement in general?) Induction is a process that can include plausible reasoning (not just absolute). 

_Statistical inference_ is an inductive process for making inferences about a population parameter, by quantifying how plausible parametre values are given the observed data or other information.

### Desired properties of plausibility measures (p.61)

<Doc cam>

Logicians have proved that any set of plausibilities that have the desired properties must operate using the rules of probability! So probability is the way to reason formally with uncertanity.

### Thoughts from your reading of Section 4.1?

Let's discuss.

### Foreshadowing

_Bayesian statistics uses the rules of probability to revise our belief given the data_.

## III. Discuss the axioms of probability (15 min)

(from Bolstad & Curran Ch.4, Section 4.3, p.64)

1. $P(A) \geq 0$ for any event $A$. (probabilities are nonnegative)
2. $P(U) = 1$. (we are certain that something will happen)
3. If $A$ and $B$ are _mutually exclusive_ events, then $P(A \cup B) = P(A) + P(B)$. (probability is _additive_ over disjoint events).

## IV. Joint probability (25 min)

### Motivating example: Four boys? What are the chances?

Suppose there are four children in a family. Which of the following sequences is most likely?

a. `bbbb`
b. `bgbg`
c. `gggg`

<Draw probablity tree on the board>

```{r, babies}
## our code here
prob_female <- 0.487
prob_male <- 1- prob_female
## probability four male births
prob_male^4
1/16
## bgbg
(prob_female)^2 * (prob_male)^2

```

Now let's discuss a realistic and (perhaps) surprising twist to the calculation:

<Insert here>

## V. Joint probability for independent events

If event $A$ and event $B$ are independent, then $P(A \cap B) = P(A) \times P(B)$. This is called the _multiplication rule_ for independent events. If this property does not hold then the events are called _dependent_.

### Mutually exclusive events versus independent events

Often learners confuse the notions of mutually exclusive (disjoint) events and independent events. Here we mean independent in the sense that one event occurring does not change the chances of another event occurring. In other words, The events behave _independently_. 
d
On the other hand, disjoint events **cannot** occur at the same time. So disjoint events (with nonzero probability) are by definition, _dependent_. This can be proved by a simple deductive proof using the multiplication rule above.

### Marginal probability

When dealing with two events (the joint setting), the probability of one event, $A$, is called its _marginal probability_. Marginal probability is really important and we'll discuss its calculation throughout the course. For a Universe with only two events, the marginal probability is found by summing its disjoint parts.

First find a partition in terms of the other event $B$:  
$A = (A \cap B) \cup (A \cap \tilde{B})$.

Then use Axiom 3:  
$P(A) = P(A \cap B) + P(A \cap \tilde{B})$.

## Closing (5 min). 

Please answer the following questions and be prepared to share with the group.

- What was the most important point of the lecture?
- What would you like to know more about?
- What was the muddiest (unclear) point of the lecture?
